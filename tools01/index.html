<!doctype html><html lang=zh-cn>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=robots content="noodp">
<title class=pjax-title>Transformers Domain Adaptation - kevinzhang'blog</title><meta name=Description content="Transformers Domain Adaptation"><meta property="og:title" content="Transformers Domain Adaptation">
<meta property="og:description" content="Transformers Domain Adaptation">
<meta property="og:type" content="article">
<meta property="og:url" content="https://kevinzhangcode.github.io/tools01/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2022-03-04T18:16:18+08:00">
<meta property="article:modified_time" content="2022-03-04T18:16:18+08:00">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Transformers Domain Adaptation">
<meta name=twitter:description content="Transformers Domain Adaptation">
<meta name=application-name content="kevinzhang'blog">
<meta name=apple-mobile-web-app-title content="kevinzhang'blog">
<meta name=theme-color content="#f8f8f8"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico>
<link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=canonical href=https://kevinzhangcode.github.io/tools01/><link rel=prev href=https://kevinzhangcode.github.io/paper02/><link rel=next href=https://kevinzhangcode.github.io/paper03/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/fontawesome-free/all.min.css>
<noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/animate/animate.min.css>
<noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Transformers Domain Adaptation","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/kevinzhangcode.github.io\/tools01\/"},"genre":"posts","keywords":"NER, NLP, Domain Adaptation, Tools","wordcount":4117,"url":"https:\/\/kevinzhangcode.github.io\/tools01\/","datePublished":"2022-03-04T18:16:18+08:00","dateModified":"2022-03-04T18:16:18+08:00","publisher":{"@type":"Organization","name":"youguan"},"author":{"@type":"Person","name":"youguan"},"description":"Transformers Domain Adaptation"}</script></head><body header-desktop header-mobile><script type=text/javascript>function setTheme(e){document.body.setAttribute("theme",e)}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(t){const e=document.getElementsByTagName("meta");for(let n=0;n<e.length;n++)if(e[n].getAttribute("name")===t)return e[n];return''}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"||e==="black"?setTheme(e):window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?setTheme("dark"):setTheme("light")}else''==="light"||''==="dark"||''==="black"?(setTheme(''),saveTheme('')):(saveTheme("auto"),window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?setTheme("dark"):setTheme("light"));let metaColors={light:"#f8f8f8",dark:"#252627",black:"#000000"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")]</script>
<div id=back-to-top></div><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop>
<div class=header-wrapper>
<div class=header-title>
<a href=/ title="kevinzhang'blog">kevinzhang'blog</a>
</div><div class=menu>
<div class=menu-inner><a class=menu-item href=/posts/> 文章 </a><a class=menu-item href=/tags/> 标签 </a><a class=menu-item href=/categories/> 分类 </a><a class=menu-item href=/about/> 关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索文章标题或内容... id=search-input-desktop>
<a href=# onclick=return!1 class="search-button search-toggle" id=search-toggle-desktop title=搜索>
<i class="fas fa-search fa-fw"></i>
</a>
<a href=# onclick=return!1 class="search-button search-clear" id=search-clear-desktop title=清空>
<i class="fas fa-times-circle fa-fw"></i>
</a>
<span class="search-button search-loading" id=search-loading-desktop>
<i class="fas fa-spinner fa-fw fa-spin"></i>
</span>
</span><a href=# onclick=return!1 class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i>
</a></div></div></div></header><header class=mobile id=header-mobile>
<div class=header-container>
<div class=header-wrapper>
<div class=header-title>
<a href=/ title="kevinzhang'blog">kevinzhang'blog</a>
</div><div class=menu-toggle id=menu-toggle-mobile>
<span></span><span></span><span></span>
</div></div><div class=menu id=menu-mobile><div class=search-wrapper>
<div class="search mobile" id=search-mobile>
<input type=text placeholder=搜索文章标题或内容... id=search-input-mobile>
<a href=# onclick=return!1 class="search-button search-toggle" id=search-toggle-mobile title=搜索>
<i class="fas fa-search fa-fw"></i>
</a>
<a href=# onclick=return!1 class="search-button search-clear" id=search-clear-mobile title=清空>
<i class="fas fa-times-circle fa-fw"></i>
</a>
<span class="search-button search-loading" id=search-loading-mobile>
<i class="fas fa-spinner fa-fw fa-spin"></i>
</span>
</div><a href=# onclick=return!1 class=search-cancel id=search-cancel-mobile>
取消
</a>
</div><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a href=# onclick=return!1 class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i>
</a></div></div></header><div class="search-dropdown desktop">
<div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile">
<div id=search-dropdown-mobile></div></div><main class=main>
<div class=container><div class=toc id=toc-auto>
<h2 class=toc-title>目录</h2><div class="toc-content always-active" id=toc-content-auto></div></div><script>document.getElementsByTagName("main")[0].setAttribute("pageStyle","normal")</script><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Transformers Domain Adaptation</h1><div class=post-meta>
<div class=post-meta-line>
<span class=post-author><i class="author fas fa-user-circle fa-fw"></i><a href=kevinzhangcode.github.io title=Author rel=author class=author>youguan</a>
</span>&nbsp;<span class=post-category>收录于 </span>&nbsp;<span class=post-category>类别 <a href=/categories/documentation/><i class="far fa-folder fa-fw"></i>documentation</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2022-03-04>2022-03-04</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime=2022-03-04>2022-03-04</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 4117 字&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 9 分钟&nbsp;</div></div><div class=featured-image><img class=lazyload data-src=https://s3.bmp.ovh/imgs/2022/03/ae09d4421b99cd53.png data-srcset="https://s3.bmp.ovh/imgs/2022/03/ae09d4421b99cd53.png, https://s3.bmp.ovh/imgs/2022/03/ae09d4421b99cd53.png 1.5x, https://s3.bmp.ovh/imgs/2022/03/ae09d4421b99cd53.png 2x" data-sizes=auto alt=https://s3.bmp.ovh/imgs/2022/03/ae09d4421b99cd53.png title="Transformers Domain Adaptation" height=auto width=auto></div><div class="details toc" id=toc-static kept>
<div class="details-summary toc-title">
<span>目录</span>
<span><i class="details-icon fas fa-angle-right"></i></span>
</div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents>
<ul>
<li><a href=#transformers-domain-adaptation>Transformers Domain Adaptation</a>
<ul>
<li>
<ul>
<li><a href=#警告>警告</a></li></ul></li><li><a href=#准备工作>准备工作</a>
<ul>
<li><a href=#安装依赖程序>安装依赖程序</a></li><li><a href=#下载demo-files>下载demo files</a></li><li><a href=#常量>常量</a></li><li><a href=#加载模型和tokenizer>加载模型和tokenizer</a></li><li><a href=#数据选择>数据选择</a></li><li><a href=#词汇扩充>词汇扩充</a></li><li><a href=#用新的词汇术语更新模型和tokenizer>用新的词汇术语更新模型和tokenizer</a></li></ul></li><li><a href=#domain-pre-training>Domain Pre-Training</a>
<ul>
<li><a href=#创建数据集>创建数据集</a></li><li><a href=#实例化trainingarguments和trainer>实例化TrainingArguments和Trainer</a></li></ul></li><li><a href=#为特定任务进行微调>为特定任务进行微调</a>
<ul>
<li><a href=#对原始数据集进行预处理形成ner数据集>对原始数据集进行预处理，形成NER数据集</a>
<ul>
<li><a href=#安装-seqeval>安装 seqeval</a></li></ul></li><li><a href=#实例化ner模型>实例化NER模型</a></li><li><a href=#为每个模型创建数据集trainingarguments和trainer>为每个模型创建数据集、TrainingArguments和Trainer</a></li><li><a href=#训练和评估da_model>训练和评估<code>da_model</code></a></li><li><a href=#训练和评估da_model_full_corpus>训练和评估<code>da_model_full_corpus</code></a></li><li><a href=#训练和评估oob_model>训练和评估<code>oob_model</code></a></li></ul></li><li><a href=#结果>结果</a></li></ul></li><li><a href=#总结>总结</a></li><li><a href=#参考>参考</a></li></ul></nav></div></div><div class=content id=content><h2 id=transformers-domain-adaptation>Transformers Domain Adaptation</h2><p>本指南说明了端到端<code>Domain Adaptation</code>工作流程，其中我们为生物医学NLP应用程序适应领域转换模型。</p><p>它展示了我们在研究中研究的两种领域自适应技术:</p><ol>
<li>数据选择 (Data Selection)</li><li>词汇量增加 (Vocabulary Augmentation)</li></ol><p>接下来，我们将演示这样一个<code>Domain Adaptation</code>的Transformer模型是如何与🤗<code>transformer</code>的训练流程兼容的，以及它如何优于开箱即用的(无<code>Domain Adaptation</code>的)模型,这些技术应用于BERT-small，但是代码库被编写成可推广到<a href=https://huggingface.co/ target=_blank rel="noopener noreffer">HuggingFace</a>支持的其他Transformer类。</p><h4 id=警告>警告</h4><p>对于本指南，由于内存和时间的限制，我们使用域内语料库的一个小得多的子集(&lt;0.05%)。</p><h3 id=准备工作>准备工作</h3><h4 id=安装依赖程序>安装依赖程序</h4><p>使用<code>pip</code>安装<code>transformers-domain-adaptation</code></p><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>pip install transformers-domain-adaptation -i https://pypi.tuna.tsinghua.edu.cn/simple
</span></span></code></pre></td></tr></table></div></div><h4 id=下载demo-files>下载demo files</h4><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>wget http://georgian-toolkit.s3.amazonaws.com/transformers-domain-adaptation/colab/files.zip
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 解压文件</span>
</span></span><span class=line><span class=cl>unzip ./files.zip
</span></span></code></pre></td></tr></table></div></div><h4 id=常量>常量</h4><p>我们首先定义一些常量，包括适当的模型卡和文本语料库的相关路径。</p><p>在<code>domain adaptation</code>的背景下，有两种类型的语料库。</p><ol>
<li>微调语料库(Fine-Tuning Corpus)</li></ol><blockquote>
<p>给定一个NLP任务（如文本分类、摘要等），这个数据集的文本部分就是微调语料库。</p></blockquote><ol start=2>
<li>在域语料库 (In-Domain Corpus)</li></ol><blockquote>
<p>这是一个无监督的文本数据集，用于领域预训练。文本领域与微调语料库的领域相同，甚至更广泛。</p></blockquote><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 预训练模型名称</span>
</span></span><span class=line><span class=cl><span class=n>model_card</span> <span class=o>=</span> <span class=s1>&#39;bert-base-uncased&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Domain-pre-training corpora 领域预训练语料</span>
</span></span><span class=line><span class=cl><span class=n>dpt_corpus_train</span> <span class=o>=</span> <span class=s1>&#39;./data/pubmed_subset_train.txt&#39;</span>
</span></span><span class=line><span class=cl><span class=n>dpt_corpus_train_data_selected</span> <span class=o>=</span> <span class=s1>&#39;./data/pubmed_subset_train_data_selected.txt&#39;</span>
</span></span><span class=line><span class=cl><span class=n>dpt_corpus_val</span> <span class=o>=</span> <span class=s1>&#39;./data/pubmed_subset_val.txt&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fine-tuning corpora</span>
</span></span><span class=line><span class=cl><span class=c1># If there are multiple downstream NLP tasks/corpora, you can concatenate those files together</span>
</span></span><span class=line><span class=cl><span class=n>ft_corpus_train</span> <span class=o>=</span> <span class=s1>&#39;./data/BC2GM_train.txt&#39;</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=加载模型和tokenizer>加载模型和tokenizer</h4><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoModelForMaskedLM</span><span class=p>,</span> <span class=n>AutoTokenizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForMaskedLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_card</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_card</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=数据选择>数据选择</h4><p>在领域预训练中，并不是所有的领域内语料库的数据都可能是有帮助的或相关的。对于不相关的文件，在最好的情况下，它不会降低领域适应模型的性能；在最坏的情况下，模型会倒退并失去宝贵的预训练信息即<code>灾难性的遗忘</code>。</p><p>因此，我们使用<a href=https://aclanthology.org/D17-1038.pdf target=_blank rel="noopener noreffer">Ruder & Plank</a>设计的各种相似性和多样性指标，从域内语料库中选择可能与下游微调数据集相关的文档。</p><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers_domain_adaptation</span> <span class=kn>import</span> <span class=n>DataSelector</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>selector</span> <span class=o>=</span> <span class=n>DataSelector</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>keep</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span>  <span class=c1># TODO Replace with `keep`</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>similarity_metrics</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;euclidean&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>diversity_metrics</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;type_token_ratio&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;entropy&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#  将文本数据加载到内存中</span>
</span></span><span class=line><span class=cl><span class=n>fine_tuning_texts</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=n>ft_corpus_train</span><span class=p>)</span><span class=o>.</span><span class=n>read_text</span><span class=p>()</span><span class=o>.</span><span class=n>splitlines</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>training_texts</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=n>dpt_corpus_train</span><span class=p>)</span><span class=o>.</span><span class=n>read_text</span><span class=p>()</span><span class=o>.</span><span class=n>splitlines</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#  在微调语料库进行fit</span>
</span></span><span class=line><span class=cl><span class=n>selector</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>fine_tuning_texts</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 从域内训练语料库中选择相关文件</span>
</span></span><span class=line><span class=cl><span class=n>selected_corpus</span> <span class=o>=</span> <span class=n>selector</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>training_texts</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 在`dpt_corpus_train_data_selected`下将选定的语料库保存到磁盘 </span>
</span></span><span class=line><span class=cl><span class=n>Path</span><span class=p>(</span><span class=n>dpt_corpus_train_data_selected</span><span class=p>)</span><span class=o>.</span><span class=n>write_text</span><span class=p>(</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>selected_corpus</span><span class=p>));</span>
</span></span></code></pre></td></tr></table></div></div><p>由于我们在<code>DataSelector</code>中指定了<code>keep=0.5</code>，所以选择的<code>语料库应该是域内语料库的一半大小</code>，包含前50%最相关的文档。</p><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>training_texts</span><span class=p>),</span> <span class=nb>len</span><span class=p>(</span><span class=n>selected_corpus</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=c1># (10000, 5000)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>selected_corpus</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>Chlorophyll content,leaf mass to per area,net photosynthetic rate and bioactive ingredients of Asarum heterotropoides var. mandshuricum,a skiophyte grown in four levels of solar irradiance were measured and analyzed in order to investigate the response of photosynthetic capability to light irradiance and other environmental factors. It suggested that the leaf mass to per area of plant was greatest value of four kinds of light irradiance and decreasing intensity of solar irradiance resulted in the decrease of leaf mass to per area at every phenological stage. At expanding leaf stage,the rate of Chla and Chlb was 3. <span class=m>11</span> when A. heterotropoides var. mandshuricum grew in full light irradiance which is similar to the rate of heliophytes,however,the rate of Chla and Chlb was below to 3. <span class=m>0</span> when they grew in shading environment. The content of Chla,Chlb and Chl<span class=o>(</span> a+b<span class=o>)</span> was the greatest value of four kinds of light irradiance and decreasing intensity of solar irradiance resulted in its decreasing remarkably<span class=o>(</span> P&lt;0. 05<span class=o>)</span>. The rate of Chla and Chlb decreased but the content of Chla,Chlb and Chl<span class=o>(</span> a+b<span class=o>)</span> increased gradually with continued shading. The maximum value of photosynthetically active radiation appeared at 10: 00-12: <span class=m>00</span> am in a day. The maximum value of net photosynthetic rate appeared at 8: 30-9: <span class=m>00</span> am and the minimum value appeared at 14: 00-14: <span class=m>30</span> pm at each phenological stage <span class=k>if</span> plants grew in full sunlight. However,when plants grew in shading,the maximum value of net photosynthetic rate appeared at about 10: <span class=m>30</span> am and the minimum value appeared at 12: 20-12: <span class=m>50</span> pm at each phenological stage. At expanding leaf stage and flowering stage,the average of net photosynthetic rate of leaves in full sunlight was remarkably higher than those in shading and it decreased greatly with decreasing of irradiance gradually<span class=o>(</span> P &lt; 0. 05<span class=o>)</span>. However,at fruiting stage,the average of net photosynthetic rate of leaves in full sunlight was lower than those in 50% and 28% full sunlight but higher than those in 12% full sunlight. All photosynthetic diurnal variation parameters of plants measured in four kinds of different irradiance at three stages were used in correlation analysis. The results suggested that no significant correlation was observed between net photosynthetic rate and photosynthetically active radiation,and significant negative correlation was observed between net photosynthetic rate and environmental temperature as well as vapor pressure deficit expect <span class=k>for</span> 12% full sunlight. Positive correlation was observed between net photosynthestic rate and relative humidity expect <span class=k>for</span> 12% full sunlight. Significant positive correlation was observed between net photosynthetic rate and stomatal conductance in the four light treatments. Only,in 12% full sunlight,the net photosynthetic rate was significantly related to photosynthetically active radiation rather than related to environmental temperature,vapor pressure deficit and relative humidity. In each light treatment,a significant positive correlation was observed between environmental temperature and vapor pressure deficit,relative humidity as well as stomatal conductance. Volatile oil content was 1. 46%,2. 16%,1. 56%,1. 30% respectively. ethanol extracts was 23. 44%,22. 45%,22. 18%,21. 12% respectively. Asarinin content was 0. 281%,0. 291%,0. 279% and 0. 252% respectively. The characteristic components of Asarum volatile oil of plant in different light treatments did not change significantly among different groups.
</span></span></code></pre></td></tr></table></div></div><h4 id=词汇扩充>词汇扩充</h4><p>我们可以扩展模型的现有词汇用以包括特定领域的术语。这样就可以在领域预训练中明确学习这种术语的表示。</p><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers_domain_adaptation</span> <span class=kn>import</span> <span class=n>VocabAugmentor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>target_vocab_size</span> <span class=o>=</span> <span class=mi>31_000</span>  <span class=c1># len(tokenizer) == 30_522</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>augmentor</span> <span class=o>=</span> <span class=n>VocabAugmentor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>cased</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>target_vocab_size</span><span class=o>=</span><span class=n>target_vocab_size</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 在微调语料库的基础上获得新的特定领域术语</span>
</span></span><span class=line><span class=cl><span class=n>new_tokens</span> <span class=o>=</span> <span class=n>augmentor</span><span class=o>.</span><span class=n>get_new_tokens</span><span class=p>(</span><span class=n>ft_corpus_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>new_tokens</span><span class=p>[:</span><span class=mi>20</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=c1># [&#39;cdna&#39;, &#39;transcriptional&#39;, &#39;tyrosine&#39;, &#39;phosphorylation&#39;, &#39;kda&#39;, &#39;homology&#39;, &#39;enhancer&#39;, &#39;assays&#39;, &#39;exon&#39;, &#39;nucleotide&#39;, &#39;genomic&#39;, &#39;encodes&#39;, &#39;deletion&#39;, &#39;polymerase&#39;, &#39;nf&#39;, &#39;cloned&#39;, &#39;recombinant&#39;, &#39;putative&#39;, &#39;transcripts&#39;, &#39;homologous&#39;]</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=用新的词汇术语更新模型和tokenizer>用新的词汇术语更新模型和tokenizer</h4><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tokenizer</span><span class=o>.</span><span class=n>add_tokens</span><span class=p>(</span><span class=n>new_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>resize_token_embeddings</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>tokenizer</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=c1># Embedding(31000, 768)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=domain-pre-training>Domain Pre-Training</h3><p><code>Domain PreTraining</code>是<code>Domain Adaptation</code>的第三步，我们在领域内语料库上用同样的预训练程序继续训练<code>Transformer模型</code>。</p><h4 id=创建数据集>创建数据集</h4><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>itertools</span> <span class=k>as</span> <span class=nn>it</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Sequence</span><span class=p>,</span> <span class=n>Union</span><span class=p>,</span> <span class=n>Generator</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>DataCollatorForLanguageModeling</span><span class=p>,</span> <span class=n>Trainer</span><span class=p>,</span> <span class=n>TrainingArguments</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>datasets</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;text&#39;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>data_files</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;train&#34;</span><span class=p>:</span> <span class=n>dpt_corpus_train_data_selected</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>        <span class=s2>&#34;val&#34;</span><span class=p>:</span> <span class=n>dpt_corpus_val</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenized_datasets</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>map</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=k>lambda</span> <span class=n>examples</span><span class=p>:</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>examples</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>],</span> <span class=n>truncation</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>max_length</span><span class=o>=</span><span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_position_embeddings</span><span class=p>),</span> 
</span></span><span class=line><span class=cl>    <span class=n>batched</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>data_collator</span> <span class=o>=</span> <span class=n>DataCollatorForLanguageModeling</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span> <span class=n>mlm</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>mlm_probability</span><span class=o>=</span><span class=mf>0.15</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=实例化trainingarguments和trainer>实例化TrainingArguments和Trainer</h4><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>training_args</span> <span class=o>=</span> <span class=n>TrainingArguments</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>output_dir</span><span class=o>=</span><span class=s2>&#34;./results/domain_pre_training&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>overwrite_output_dir</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_steps</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_eval_batch_size</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>evaluation_strategy</span><span class=o>=</span><span class=s2>&#34;steps&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_steps</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_total_limit</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>logging_steps</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>seed</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># fp16=True,</span>
</span></span><span class=line><span class=cl>    <span class=n>dataloader_num_workers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>disable_tqdm</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>trainer</span> <span class=o>=</span> <span class=n>Trainer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>=</span><span class=n>training_args</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=o>=</span><span class=n>tokenized_datasets</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_dataset</span><span class=o>=</span><span class=n>tokenized_datasets</span><span class=p>[</span><span class=s1>&#39;val&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>data_collator</span><span class=o>=</span><span class=n>data_collator</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>  <span class=c1># 这个标记器有新的tokens</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 进行训练</span>
</span></span><span class=line><span class=cl><span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p><code>训练结果</code></p><table>
<thead>
<tr>
<th>Step</th><th>Training Loss</th><th>Validation Loss</th><th>Runtime</th><th>Samples Per Second</th></tr></thead><tbody>
<tr>
<td>50</td><td>2.813800</td><td>2.409768</td><td>75.058500</td><td>13.323000</td></tr><tr>
<td>100</td><td>2.520700</td><td>2.342451</td><td>74.257200</td><td>13.467000</td></tr></tbody></table><h3 id=为特定任务进行微调>为特定任务进行微调</h3><p>我们可以为<code>HuggingFace</code>支持的任何微调任务插入我们的<code>domain adaptation</code>模型。在本指南中，我们将在BC2GM数据集（一个流行的生物医学基准数据集）上比较一个开箱即用（OOB）模型与一个领域适应模型在命名实体识别方面的表现。用于NER预处理和评估的实用函数改编自HuggingFace的<a href=https://github.com/huggingface/notebooks/blob/master/examples/token_classification.ipynb target=_blank rel="noopener noreffer">NER微调示例笔记</a>。</p><h4 id=对原始数据集进行预处理形成ner数据集>对原始数据集进行预处理，形成NER数据集</h4><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>NamedTuple</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>functools</span> <span class=kn>import</span> <span class=n>partial</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing_extensions</span> <span class=kn>import</span> <span class=n>Literal</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>Dataset</span><span class=p>,</span> <span class=n>load_dataset</span><span class=p>,</span> <span class=n>load_metric</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Example</span><span class=p>(</span><span class=n>NamedTuple</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>token</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl>    <span class=n>label</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_ner_dataset</span><span class=p>(</span><span class=n>mode</span><span class=p>:</span> <span class=n>Literal</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>,</span> <span class=s1>&#39;val&#39;</span><span class=p>,</span> <span class=s1>&#39;test&#39;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>    <span class=n>file</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;data/BC2GM_</span><span class=si>{</span><span class=n>mode</span><span class=si>}</span><span class=s2>.tsv&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>examples</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>file</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>token</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>label</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>line</span> <span class=ow>in</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>line</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=o>==</span> <span class=s2>&#34;&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>examples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>Example</span><span class=p>(</span><span class=n>token</span><span class=o>=</span><span class=n>token</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>))</span>
</span></span><span class=line><span class=cl>                <span class=n>token</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>                <span class=n>label</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=n>t</span><span class=p>,</span> <span class=n>l</span> <span class=o>=</span> <span class=n>line</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\t</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>token</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>t</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>label</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>l</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>    <span class=n>res</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=o>*</span><span class=p>[(</span><span class=n>ex</span><span class=o>.</span><span class=n>token</span><span class=p>,</span> <span class=n>ex</span><span class=o>.</span><span class=n>label</span><span class=p>)</span> <span class=k>for</span> <span class=n>ex</span> <span class=ow>in</span> <span class=n>examples</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=n>d</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;token&#39;</span><span class=p>:</span> <span class=n>res</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=s1>&#39;labels&#39;</span><span class=p>:</span> <span class=n>res</span><span class=p>[</span><span class=mi>1</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>Dataset</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span><span class=n>d</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>tokenize_and_align_labels</span><span class=p>(</span><span class=n>examples</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenized_inputs</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>examples</span><span class=p>[</span><span class=s2>&#34;token&#34;</span><span class=p>],</span> <span class=n>truncation</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>is_split_into_words</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>label_to_id</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>reversed</span><span class=p>,</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>label_list</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>examples</span><span class=p>[</span><span class=s2>&#34;labels&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=n>word_ids</span> <span class=o>=</span> <span class=n>tokenized_inputs</span><span class=o>.</span><span class=n>word_ids</span><span class=p>(</span><span class=n>batch_index</span><span class=o>=</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>previous_word_idx</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=n>label_ids</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>word_idx</span> <span class=ow>in</span> <span class=n>word_ids</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 特殊标记有一个单词ID，是None。我们将标签设置为-100，因此它们在损失函数中被自动忽略了。</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>word_idx</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>label_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=o>-</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 我们为每个词的第一个标记设置标签。</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=n>word_idx</span> <span class=o>!=</span> <span class=n>previous_word_idx</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>label_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>label_to_id</span><span class=p>[</span><span class=n>label</span><span class=p>[</span><span class=n>word_idx</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>            <span class=c1># 对于一个词中的其他标记，我们根据label_all_tokens的标志，将标签设置为当前标签或-100。</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>label_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>label_to_id</span><span class=p>[</span><span class=n>label</span><span class=p>[</span><span class=n>word_idx</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>            <span class=n>previous_word_idx</span> <span class=o>=</span> <span class=n>word_idx</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>labels</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>label_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>tokenized_inputs</span><span class=p>[</span><span class=s2>&#34;labels&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>labels</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>tokenized_inputs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_metrics</span><span class=p>(</span><span class=n>p</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>predictions</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>p</span>
</span></span><span class=line><span class=cl>    <span class=n>predictions</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 移除被忽略的索引（特殊标记）。</span>
</span></span><span class=line><span class=cl>    <span class=n>true_predictions</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=n>label_list</span><span class=p>[</span><span class=n>p</span><span class=p>]</span> <span class=k>for</span> <span class=p>(</span><span class=n>p</span><span class=p>,</span> <span class=n>l</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>prediction</span><span class=p>,</span> <span class=n>label</span><span class=p>)</span> <span class=k>if</span> <span class=n>l</span> <span class=o>!=</span> <span class=o>-</span><span class=mi>100</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>prediction</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>true_labels</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=n>label_list</span><span class=p>[</span><span class=n>l</span><span class=p>]</span> <span class=k>for</span> <span class=p>(</span><span class=n>p</span><span class=p>,</span> <span class=n>l</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>prediction</span><span class=p>,</span> <span class=n>label</span><span class=p>)</span> <span class=k>if</span> <span class=n>l</span> <span class=o>!=</span> <span class=o>-</span><span class=mi>100</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>prediction</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>metric</span><span class=o>.</span><span class=n>compute</span><span class=p>(</span><span class=n>predictions</span><span class=o>=</span><span class=n>true_predictions</span><span class=p>,</span> <span class=n>references</span><span class=o>=</span><span class=n>true_labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;precision&#34;</span><span class=p>:</span> <span class=n>results</span><span class=p>[</span><span class=s2>&#34;overall_precision&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;recall&#34;</span><span class=p>:</span> <span class=n>results</span><span class=p>[</span><span class=s2>&#34;overall_recall&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;f1&#34;</span><span class=p>:</span> <span class=n>results</span><span class=p>[</span><span class=s2>&#34;overall_f1&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;accuracy&#34;</span><span class=p>:</span> <span class=n>results</span><span class=p>[</span><span class=s2>&#34;overall_accuracy&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=安装-seqeval>安装 seqeval</h5><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>pip install seqeval
</span></span></code></pre></td></tr></table></div></div><p><a href=https://pypi.org/project/seqeval/ target=_blank rel="noopener noreffer">seqeval</a>是一个用于序列标记评估的Python框架，可以评估分块任务的性能，如命名实体识别、部分语音标记、语义角色标记等。</p><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>label_list</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;O&#34;</span><span class=p>,</span> <span class=s2>&#34;B&#34;</span><span class=p>,</span> <span class=s2>&#34;I&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>metric</span> <span class=o>=</span> <span class=n>load_metric</span><span class=p>(</span><span class=s1>&#39;seqeval&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>train_dataset</span> <span class=o>=</span> <span class=n>load_ner_dataset</span><span class=p>(</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>val_dataset</span> <span class=o>=</span> <span class=n>load_ner_dataset</span><span class=p>(</span><span class=s1>&#39;val&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>test_dataset</span> <span class=o>=</span> <span class=n>load_ner_dataset</span><span class=p>(</span><span class=s1>&#39;test&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>val_dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>test_dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=c1># {&#39;token&#39;: [[&#39;Immunohistochemical&#39;, &#39;staining&#39;, &#39;was&#39;, &#39;positive&#39;, &#39;for&#39;, &#39;S&#39;, &#39;-&#39;, &#39;100&#39;, &#39;in&#39;, &#39;all&#39;, &#39;9&#39;, &#39;cases&#39;, &#39;stained&#39;, &#39;,&#39;, &#39;positive&#39;, &#39;for&#39;, &#39;HMB&#39;, &#39;-&#39;, &#39;45&#39;, &#39;in&#39;, &#39;9&#39;, &#39;(&#39;, &#39;90&#39;, &#39;%&#39;, &#39;)&#39;, &#39;of&#39;, &#39;10&#39;, &#39;,&#39;, &#39;and&#39;, &#39;negative&#39;, &#39;for&#39;, &#39;cytokeratin&#39;, &#39;in&#39;, &#39;all&#39;, &#39;9&#39;, &#39;cases&#39;, &#39;in&#39;, &#39;which&#39;, &#39;myxoid&#39;, &#39;melanoma&#39;, &#39;remained&#39;, &#39;in&#39;, &#39;the&#39;, &#39;block&#39;, &#39;after&#39;, &#39;previous&#39;, &#39;sections&#39;, &#39;.&#39;]], &#39;labels&#39;: [[&#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B&#39;, &#39;I&#39;, &#39;I&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B&#39;, &#39;I&#39;, &#39;I&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;]]}</span>
</span></span><span class=line><span class=cl><span class=c1># {&#39;token&#39;: [[&#39;Joys&#39;, &#39;and&#39;, &#39;F&#39;, &#39;.&#39;]], &#39;labels&#39;: [[&#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;]]}</span>
</span></span><span class=line><span class=cl><span class=c1># {&#39;token&#39;: [[&#39;Physical&#39;, &#39;mapping&#39;, &#39;220&#39;, &#39;kb&#39;, &#39;centromeric&#39;, &#39;of&#39;, &#39;the&#39;, &#39;human&#39;, &#39;MHC&#39;, &#39;and&#39;, &#39;DNA&#39;, &#39;sequence&#39;, &#39;analysis&#39;, &#39;of&#39;, &#39;the&#39;, &#39;43&#39;, &#39;-&#39;, &#39;kb&#39;, &#39;segment&#39;, &#39;including&#39;, &#39;the&#39;, &#39;RING1&#39;, &#39;,&#39;, &#39;HKE6&#39;, &#39;,&#39;, &#39;and&#39;, &#39;HKE4&#39;, &#39;genes&#39;, &#39;.&#39;]], &#39;labels&#39;: [[&#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B&#39;, &#39;I&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B&#39;, &#39;O&#39;, &#39;B&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B&#39;, &#39;I&#39;, &#39;O&#39;]]}</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=实例化ner模型>实例化NER模型</h4><p>在此，我们实例化了三个特定任务的NER模型进行比较:</p><ol>
<li>
<p><code>da_model</code>: 我们在本指南中刚刚训练的一个<code>Domain Adaptation</code>的NER模型</p></li><li>
<p><code>da_full_corpus_model</code>: 同样的领域适应性NER模型，只是它是在完整的领域内训练语料库上训练的。</p></li><li>
<p><code>oob_model</code>: 一个开箱即用的BERT-NER模型（没有经过Domain Adaptation）。</p></li></ol><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoModelForTokenClassification</span><span class=p>,</span> <span class=n>DataCollatorForTokenClassification</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>best_checkpoint</span> <span class=o>=</span> <span class=s1>&#39;./results/domain_pre_training/checkpoint-100&#39;</span>
</span></span><span class=line><span class=cl><span class=n>da_model</span> <span class=o>=</span> <span class=n>AutoModelForTokenClassification</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>best_checkpoint</span><span class=p>,</span> <span class=n>num_labels</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>label_list</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>da_full_corpus_model</span> <span class=o>=</span> <span class=n>AutoModelForTokenClassification</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s1>&#39;./domain-adapted-bert&#39;</span><span class=p>,</span> <span class=n>num_labels</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>label_list</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>full_corpus_tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s1>&#39;./domain-adapted-bert&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>oob_tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_card</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>oob_model</span> <span class=o>=</span> <span class=n>AutoModelForTokenClassification</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_card</span><span class=p>,</span> <span class=n>num_labels</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>label_list</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=为每个模型创建数据集trainingarguments和trainer>为每个模型创建数据集、TrainingArguments和Trainer</h4><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Dict</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>Dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>preprocess_datasets</span><span class=p>(</span><span class=n>tokenizer</span><span class=p>,</span> <span class=o>**</span><span class=n>datasets</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Dataset</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenize_ner</span> <span class=o>=</span> <span class=n>partial</span><span class=p>(</span><span class=n>tokenize_and_align_labels</span><span class=p>,</span> <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=n>k</span><span class=p>:</span> <span class=n>ds</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>tokenize_ner</span><span class=p>,</span> <span class=n>batched</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>ds</span> <span class=ow>in</span> <span class=n>datasets</span><span class=o>.</span><span class=n>items</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>######################</span>
</span></span><span class=line><span class=cl><span class=c1>##### `da_model` #####</span>
</span></span><span class=line><span class=cl><span class=c1>######################</span>
</span></span><span class=line><span class=cl><span class=n>da_datasets</span> <span class=o>=</span> <span class=n>preprocess_datasets</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>train</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>val</span><span class=o>=</span><span class=n>val_dataset</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>test</span><span class=o>=</span><span class=n>test_dataset</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>da_datasets</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>training_args</span> <span class=o>=</span> <span class=n>TrainingArguments</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>output_dir</span><span class=o>=</span><span class=s2>&#34;./results/domain_adapted_fine_tuning&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>overwrite_output_dir</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_train_epochs</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_eval_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>evaluation_strategy</span><span class=o>=</span><span class=s2>&#34;steps&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_steps</span><span class=o>=</span><span class=mi>200</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_total_limit</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>logging_steps</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>seed</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>fp16</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dataloader_num_workers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>disable_tqdm</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>da_trainer</span> <span class=o>=</span> <span class=n>Trainer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=n>da_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>=</span><span class=n>training_args</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=o>=</span><span class=n>da_datasets</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_dataset</span><span class=o>=</span><span class=n>da_datasets</span><span class=p>[</span><span class=s1>&#39;val&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>data_collator</span><span class=o>=</span><span class=n>DataCollatorForTokenClassification</span><span class=p>(</span><span class=n>tokenizer</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>  <span class=c1># This tokenizer has new tokens</span>
</span></span><span class=line><span class=cl>    <span class=n>compute_metrics</span><span class=o>=</span><span class=n>compute_metrics</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>##################################</span>
</span></span><span class=line><span class=cl><span class=c1>##### `da_model_full_corpus` #####</span>
</span></span><span class=line><span class=cl><span class=c1>##################################</span>
</span></span><span class=line><span class=cl><span class=n>da_full_corpus_datasets</span> <span class=o>=</span> <span class=n>preprocess_datasets</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>full_corpus_tokenizer</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>train</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>val</span><span class=o>=</span><span class=n>val_dataset</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>test</span><span class=o>=</span><span class=n>test_dataset</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>training_args</span> <span class=o>=</span> <span class=n>TrainingArguments</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>output_dir</span><span class=o>=</span><span class=s2>&#34;./results/domain_adapted_full_corpus_fine_tuning&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>overwrite_output_dir</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_train_epochs</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_eval_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>evaluation_strategy</span><span class=o>=</span><span class=s2>&#34;steps&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_steps</span><span class=o>=</span><span class=mi>200</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_total_limit</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>logging_steps</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>seed</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>fp16</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dataloader_num_workers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>disable_tqdm</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>da_full_corpus_trainer</span> <span class=o>=</span> <span class=n>Trainer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=n>da_full_corpus_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>=</span><span class=n>training_args</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=o>=</span><span class=n>da_full_corpus_datasets</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_dataset</span><span class=o>=</span><span class=n>da_full_corpus_datasets</span><span class=p>[</span><span class=s1>&#39;val&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>data_collator</span><span class=o>=</span><span class=n>DataCollatorForTokenClassification</span><span class=p>(</span><span class=n>full_corpus_tokenizer</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>full_corpus_tokenizer</span><span class=p>,</span>  <span class=c1># This tokenizer has new tokens</span>
</span></span><span class=line><span class=cl>    <span class=n>compute_metrics</span><span class=o>=</span><span class=n>compute_metrics</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#######################</span>
</span></span><span class=line><span class=cl><span class=c1>##### `oob_model` #####</span>
</span></span><span class=line><span class=cl><span class=c1>#######################</span>
</span></span><span class=line><span class=cl><span class=n>oob_datasets</span> <span class=o>=</span> <span class=n>preprocess_datasets</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>oob_tokenizer</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>train</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>val</span><span class=o>=</span><span class=n>val_dataset</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>test</span><span class=o>=</span><span class=n>test_dataset</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>training_args</span> <span class=o>=</span> <span class=n>TrainingArguments</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>output_dir</span><span class=o>=</span><span class=s2>&#34;./results/out_of_the_box_fine_tuning&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>overwrite_output_dir</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_train_epochs</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_eval_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>evaluation_strategy</span><span class=o>=</span><span class=s2>&#34;steps&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_steps</span><span class=o>=</span><span class=mi>200</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_total_limit</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>logging_steps</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>seed</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>fp16</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dataloader_num_workers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>disable_tqdm</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>oob_model_trainer</span> <span class=o>=</span> <span class=n>Trainer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=n>oob_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>=</span><span class=n>training_args</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=o>=</span><span class=n>oob_datasets</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_dataset</span><span class=o>=</span><span class=n>oob_datasets</span><span class=p>[</span><span class=s1>&#39;val&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>data_collator</span><span class=o>=</span><span class=n>DataCollatorForTokenClassification</span><span class=p>(</span><span class=n>oob_tokenizer</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>oob_tokenizer</span><span class=p>,</span>  <span class=c1># 这是原始的tokenizer（没有特定领域的token）。</span>
</span></span><span class=line><span class=cl>    <span class=n>compute_metrics</span><span class=o>=</span><span class=n>compute_metrics</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=训练和评估da_model>训练和评估<code>da_model</code></h4><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>da_trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>da_trainer</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>da_datasets</span><span class=p>[</span><span class=s1>&#39;test&#39;</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>训练结果</p><table>
<thead>
<tr>
<th>Step</th><th>Training Loss</th><th>Validation Loss</th><th>Precision</th><th>Recall</th><th>F1</th><th>Accuracy</th><th>Runtime</th><th>Samples Per Second</th></tr></thead><tbody>
<tr>
<td>100</td><td>0.258000</td><td>0.156976</td><td>0.621130</td><td>0.604061</td><td>0.612477</td><td>0.941589</td><td>64.652200</td><td>38.962000</td></tr><tr>
<td>200</td><td>0.148500</td><td>0.130968</td><td>0.689895</td><td>0.693156</td><td>0.691522</td><td>0.951615</td><td>64.609800</td><td>38.988000</td></tr><tr>
<td>300</td><td>0.131800</td><td>0.119317</td><td>0.671880</td><td>0.774549</td><td>0.719571</td><td>0.954099</td><td>64.629700</td><td>38.976000</td></tr><tr>
<td>400</td><td>0.116800</td><td>0.108599</td><td>0.738141</td><td>0.743567</td><td>0.740844</td><td>0.959777</td><td>64.621000</td><td>38.981000</td></tr><tr>
<td>500</td><td>0.078600</td><td>0.106925</td><td>0.749023</td><td>0.771574</td><td>0.760131</td><td>0.962172</td><td>64.869500</td><td>38.832000</td></tr><tr>
<td>600</td><td>0.074800</td><td>0.098790</td><td>0.749081</td><td>0.784351</td><td>0.766310</td><td>0.962727</td><td>64.517500</td><td>39.044000</td></tr><tr>
<td>700</td><td>0.073000</td><td>0.099364</td><td>0.763633</td><td>0.784351</td><td>0.773854</td><td>0.964268</td><td>64.496200</td><td>39.057000</td></tr></tbody></table><h4 id=训练和评估da_model_full_corpus>训练和评估<code>da_model_full_corpus</code></h4><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>da_full_corpus_trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>da_full_corpus_trainer</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>da_full_corpus_datasets</span><span class=p>[</span><span class=s1>&#39;test&#39;</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p><code>结果</code></p><table>
<thead>
<tr>
<th style=text-align:right>Step</th><th style=text-align:right>Training Loss</th><th style=text-align:right>Validation Loss</th><th style=text-align:right>Precision</th><th style=text-align:right>Recall</th><th style=text-align:right>F1</th><th style=text-align:right>Accuracy</th><th style=text-align:right>Runtime</th><th style=text-align:right>Samples Per Second</th></tr></thead><tbody>
<tr>
<td style=text-align:right>100</td><td style=text-align:right>0.231900</td><td style=text-align:right>0.127792</td><td style=text-align:right>0.671435</td><td style=text-align:right>0.829809</td><td style=text-align:right>0.742268</td><td style=text-align:right>0.952202</td><td style=text-align:right>8.246900</td><td style=text-align:right>305.450000</td></tr><tr>
<td style=text-align:right>200</td><td style=text-align:right>0.108300</td><td style=text-align:right>0.086280</td><td style=text-align:right>0.817341</td><td style=text-align:right>0.826690</td><td style=text-align:right>0.821989</td><td style=text-align:right>0.968876</td><td style=text-align:right>8.064200</td><td style=text-align:right>312.366000</td></tr><tr>
<td style=text-align:right>300</td><td style=text-align:right>0.089600</td><td style=text-align:right>0.083020</td><td style=text-align:right>0.807372</td><td style=text-align:right>0.838995</td><td style=text-align:right>0.822879</td><td style=text-align:right>0.969839</td><td style=text-align:right>8.014300</td><td style=text-align:right>314.313000</td></tr><tr>
<td style=text-align:right>400</td><td style=text-align:right>0.080600</td><td style=text-align:right>0.078229</td><td style=text-align:right>0.801577</td><td style=text-align:right>0.880763</td><td style=text-align:right>0.839306</td><td style=text-align:right>0.971885</td><td style=text-align:right>8.141400</td><td style=text-align:right>309.405000</td></tr><tr>
<td style=text-align:right>500</td><td style=text-align:right>0.050800</td><td style=text-align:right>0.075855</td><td style=text-align:right>0.843227</td><td style=text-align:right>0.864125</td><td style=text-align:right>0.853548</td><td style=text-align:right>0.973716</td><td style=text-align:right>8.172500</td><td style=text-align:right>308.230000</td></tr><tr>
<td style=text-align:right>600</td><td style=text-align:right>0.052500</td><td style=text-align:right>0.075362</td><td style=text-align:right>0.845051</td><td style=text-align:right>0.858232</td><td style=text-align:right>0.851591</td><td style=text-align:right>0.973550</td><td style=text-align:right>8.057900</td><td style=text-align:right>312.611000</td></tr><tr>
<td style=text-align:right>700</td><td style=text-align:right>0.047400</td><td style=text-align:right>0.073649</td><td style=text-align:right>0.851391</td><td style=text-align:right>0.864818</td><td style=text-align:right>0.858052</td><td style=text-align:right>0.974442</td><td style=text-align:right>8.029400</td><td style=text-align:right></td></tr></tbody></table><h4 id=训练和评估oob_model>训练和评估<code>oob_model</code></h4><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>oob_model_trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>oob_model_trainer</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>oob_datasets</span><span class=p>[</span><span class=s1>&#39;test&#39;</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p><code>结果</code></p><table>
<thead>
<tr>
<th style=text-align:right>Step</th><th style=text-align:right>Training Loss</th><th style=text-align:right>Validation Loss</th><th style=text-align:right>Precision</th><th style=text-align:right>Recall</th><th style=text-align:right>F1</th><th style=text-align:right>Accuracy</th><th style=text-align:right>Runtime</th><th style=text-align:right>Samples Per Second</th></tr></thead><tbody>
<tr>
<td style=text-align:right>100</td><td style=text-align:right>0.229200</td><td style=text-align:right>0.133785</td><td style=text-align:right>0.678159</td><td style=text-align:right>0.803118</td><td style=text-align:right>0.735368</td><td style=text-align:right>0.947964</td><td style=text-align:right>8.654700</td><td style=text-align:right>291.056000</td></tr><tr>
<td style=text-align:right>200</td><td style=text-align:right>0.135200</td><td style=text-align:right>0.109798</td><td style=text-align:right>0.745311</td><td style=text-align:right>0.825984</td><td style=text-align:right>0.783576</td><td style=text-align:right>0.957941</td><td style=text-align:right>8.660700</td><td style=text-align:right>290.855000</td></tr><tr>
<td style=text-align:right>300</td><td style=text-align:right>0.117200</td><td style=text-align:right>0.099117</td><td style=text-align:right>0.782186</td><td style=text-align:right>0.837120</td><td style=text-align:right>0.808721</td><td style=text-align:right>0.962326</td><td style=text-align:right>8.699700</td><td style=text-align:right>289.550000</td></tr><tr>
<td style=text-align:right>400</td><td style=text-align:right>0.101300</td><td style=text-align:right>0.095984</td><td style=text-align:right>0.827210</td><td style=text-align:right>0.822420</td><td style=text-align:right>0.824808</td><td style=text-align:right>0.965538</td><td style=text-align:right>8.725000</td><td style=text-align:right>288.710000</td></tr><tr>
<td style=text-align:right>500</td><td style=text-align:right>0.069000</td><td style=text-align:right>0.103978</td><td style=text-align:right>0.788701</td><td style=text-align:right>0.845731</td><td style=text-align:right>0.816221</td><td style=text-align:right>0.961440</td><td style=text-align:right>8.690600</td><td style=text-align:right>289.853000</td></tr><tr>
<td style=text-align:right>600</td><td style=text-align:right>0.064100</td><td style=text-align:right>0.092247</td><td style=text-align:right>0.827396</td><td style=text-align:right>0.848404</td><td style=text-align:right>0.837768</td><td style=text-align:right>0.967232</td><td style=text-align:right>8.671200</td><td style=text-align:right>290.501000</td></tr><tr>
<td style=text-align:right>700</td><td style=text-align:right>0.064400</td><td style=text-align:right>0.090411</td><td style=text-align:right>0.829128</td><td style=text-align:right>0.853749</td><td style=text-align:right>0.841258</td><td style=text-align:right>0.968306</td><td style=text-align:right>8.821600</td><td style=text-align:right>285.549000</td></tr></tbody></table><h3 id=结果>结果</h3><p>我们看到，在这三个模型中，<code>da_full_corpus_model</code>（在整个域内训练语料库上进行了域调整）在测试F1得分上比<code>oob_model</code>高出<code>2%</code>以上。事实上，这个<code>da_full_corpus_model</code>模型是我们训练的在BC2GM上优于SOTA的许多领域适应模型之一。</p><p>此外，<code>da_model</code>的表现也低于<code>oob_model</code>。这是可以预期的，因为<code>da_model</code>在本指南中经历了最小的领域预训练。</p><h2 id=总结>总结</h2><p>在本指南中，你已经看到了如何使用 &ldquo;DataSelector &ldquo;和 &ldquo;VocabAugmentor&rdquo;，通过分别执行数据选择和词汇扩展，对变压器模型进行领域调整。</p><p>你还看到它们与HuggingFace的所有产品兼容。变换器&rdquo;、&ldquo;标记器 &ldquo;和 &ldquo;数据集&rdquo;。</p><p>最后表明，在完整的领域内语料库上进行领域适应的模型比开箱即用的模型表现更好。</p><h2 id=参考>参考</h2><p><a href=https://github.com/georgian-io/Transformers-Domain-Adaptation target=_blank rel="noopener noreffer">Transformers-Domain-Adaptation</a></p><p><a href="https://colab.research.google.com/drive/1RAigUDEPpwdfgbzDII0C6-nmtoqgKABA?usp=sharing" target=_blank rel="noopener noreffer">Guide to Transformers Domain Adaptation</a></p></div><div class=post-footer id=post-footer>
<div class=post-info>
<div class=post-info-line>
<div class=post-info-mod>
<span>更新于 2022-03-04</span>
</div><div class=post-info-license></div></div><div class=post-info-line>
<div class=post-info-md></div><div class=post-info-share>
<span><a href=# onclick=return!1 title="分享到 Twitter" data-sharer=twitter data-url=https://kevinzhangcode.github.io/tools01/ data-title="Transformers Domain Adaptation" data-hashtags="NER,NLP,Domain Adaptation,Tools"><i class="fab fa-twitter fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Facebook" data-sharer=facebook data-url=https://kevinzhangcode.github.io/tools01/ data-hashtag=NER><i class="fab fa-facebook-square fa-fw"></i></a><a href=# onclick=return!1 title="分享到 WhatsApp" data-sharer=whatsapp data-url=https://kevinzhangcode.github.io/tools01/ data-title="Transformers Domain Adaptation" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Line" data-sharer=line data-url=https://kevinzhangcode.github.io/tools01/ data-title="Transformers Domain Adaptation"><i data-svg-src=/lib/simple-icons/icons/line.min.svg></i></a><a href=# onclick=return!1 title="分享到 微博" data-sharer=weibo data-url=https://kevinzhangcode.github.io/tools01/ data-title="Transformers Domain Adaptation" data-image=https://s3.bmp.ovh/imgs/2022/03/ae09d4421b99cd53.png><i class="fab fa-weibo fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Myspace" data-sharer=myspace data-url=https://kevinzhangcode.github.io/tools01/ data-title="Transformers Domain Adaptation" data-description="Transformers Domain Adaptation"><i data-svg-src=/lib/simple-icons/icons/myspace.min.svg></i></a><a href=# onclick=return!1 title="分享到 Blogger" data-sharer=blogger data-url=https://kevinzhangcode.github.io/tools01/ data-title="Transformers Domain Adaptation" data-description="Transformers Domain Adaptation"><i class="fab fa-blogger fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Evernote" data-sharer=evernote data-url=https://kevinzhangcode.github.io/tools01/ data-title="Transformers Domain Adaptation"><i class="fab fa-evernote fa-fw"></i></a></span>
</div></div></div><div class=post-info-more>
<section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/ner/>NER</a>,&nbsp;<a href=/tags/nlp/>NLP</a>,&nbsp;<a href=/tags/domain-adaptation/>Domain Adaptation</a>,&nbsp;<a href=/tags/tools/>Tools</a></section><section>
<span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span>
</section></div><div class=post-nav><a href=/paper02/ class=prev rel=prev title="ACl-2021-Learning Domain-Specialised Representations for Cross-Lingual Biomedical Entity Linking"><i class="fas fa-angle-left fa-fw"></i>ACl-2021-Learning Domain-Specialised Representations for Cross-Lingual Biomedical Entity Linking</a>
<a href=/paper03/ class=next rel=next title="ACl-2021-Cross-Domain NER using Cross-Domain Language Modeling">ACl-2021-Cross-Domain NER using Cross-Domain Language Modeling<i class="fas fa-angle-right fa-fw"></i></a></div></div></article></div></main><footer class=footer>
<div class=footer-container><div class=footer-line>由 <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.93.3">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/HEIGE-PCloud/DoIt target=_blank rel="noopener noreffer" title="DoIt 0.2.13"><i class="far fa-edit fa-fw"></i> DoIt</a>
</div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=kevinzhangcode.github.io target=_blank rel="noopener noreferrer">youguan</a></span></div></div></footer></div><div id=fixed-buttons><a href=#back-to-top id=back-to-top-button class=fixed-button title=回到顶部>
<i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title=查看评论>
<i class="fas fa-comment fa-fw"></i>
</a>
</div><div class=assets><script type=text/javascript src=/lib/autocomplete/autocomplete.min.js></script><script type=text/javascript src=/lib/lunr/lunr.min.js></script><script type=text/javascript src=/lib/lunr/lunr.stemmer.support.min.js></script><script type=text/javascript src=/lib/lunr/lunr.zh.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/topbar/topbar.min.js></script><script type=text/javascript src=/lib/pjax/pjax.min.js></script><script type=text/javascript src=/js/theme.min.js></script></div><div class=pjax-assets><script type=text/javascript src=/lib/lightgallery/lightgallery.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-thumbnail.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-zoom.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js></script><script type=text/javascript src=/lib/katex/auto-render.min.js></script><script type=text/javascript src=/lib/katex/copy-tex.min.js></script><script type=text/javascript src=/lib/katex/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:1e3},comment:{},lightGallery:{actualSize:!1,exThumbImage:"data-thumbnail",hideBarsDelay:2e3,selector:".lightgallery",speed:400,thumbContHeight:80,thumbWidth:80,thumbnail:!0},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",lunrLanguageCode:"zh",lunrSegmentitURL:"/lib/lunr/lunr.segmentit.js",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"lunr"},sharerjs:!0}</script><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/lightgallery/lightgallery.min.css>
<noscript><link rel=stylesheet href=/lib/lightgallery/lightgallery.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/katex.min.css>
<noscript><link rel=stylesheet href=/lib/katex/katex.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.css>
<noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.css></noscript></div></body></html>