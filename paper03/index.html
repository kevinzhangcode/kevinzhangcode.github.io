<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title class=pjax-title>ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling - kevinzhang'blog</title><meta name=Description content="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling"><meta property="og:title" content="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling"><meta property="og:description" content="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling"><meta property="og:type" content="article"><meta property="og:url" content="https://kevinzhangcode.github.io/paper03/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-03-10T19:02:27+08:00"><meta property="article:modified_time" content="2022-03-10T19:02:27+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling"><meta name=twitter:description content="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling"><meta name=application-name content="kevinzhang'blog"><meta name=apple-mobile-web-app-title content="kevinzhang'blog"><meta name=theme-color content="#f8f8f8"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=canonical href=https://kevinzhangcode.github.io/paper03/><link rel=prev href=https://kevinzhangcode.github.io/tools01/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/fontawesome-free/all.min.css><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/animate/animate.min.css><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/kevinzhangcode.github.io\/paper03\/"},"genre":"posts","keywords":"NER, NLP, Domain Adaptation","wordcount":2876,"url":"https:\/\/kevinzhangcode.github.io\/paper03\/","datePublished":"2022-03-10T19:02:27+08:00","dateModified":"2022-03-10T19:02:27+08:00","publisher":{"@type":"Organization","name":"youguan"},"author":{"@type":"Person","name":"youguan"},"description":"ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling"}</script></head><body header-desktop header-mobile><script type=text/javascript>function setTheme(e){document.body.setAttribute("theme",e)}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(t){const e=document.getElementsByTagName("meta");for(let n=0;n<e.length;n++)if(e[n].getAttribute("name")===t)return e[n];return''}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"||e==="black"?setTheme(e):window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?setTheme("dark"):setTheme("light")}else''==="light"||''==="dark"||''==="black"?(setTheme(''),saveTheme('')):(saveTheme("auto"),window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?setTheme("dark"):setTheme("light"));let metaColors={light:"#f8f8f8",dark:"#252627",black:"#000000"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")]</script><div id=back-to-top></div><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="kevinzhang'blog">kevinzhang'blog</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/>关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索文章标题或内容... id=search-input-desktop>
<a href=# onclick=return!1 class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fas fa-search fa-fw"></i></a>
<a href=# onclick=return!1 class="search-button search-clear" id=search-clear-desktop title=清空><i class="fas fa-times-circle fa-fw"></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i></span>
</span><a href=# onclick=return!1 class="menu-item theme-switch" title=切换主题><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="kevinzhang'blog">kevinzhang'blog</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容... id=search-input-mobile>
<a href=# onclick=return!1 class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fas fa-search fa-fw"></i></a>
<a href=# onclick=return!1 class="search-button search-clear" id=search-clear-mobile title=清空><i class="fas fa-times-circle fa-fw"></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=# onclick=return!1 class=search-cancel id=search-cancel-mobile>取消</a></div><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a href=# onclick=return!1 class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class="toc-content always-active" id=toc-content-auto></div></div><script>document.getElementsByTagName("main")[0].setAttribute("pageStyle","normal")</script><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling</h1><div class=post-meta><div class=post-meta-line><span class=post-author><i class="author fas fa-user-circle fa-fw"></i><a href=kevinzhangcode.github.io title=Author rel=author class=author>youguan</a>
</span>&nbsp;<span class=post-category>收录于 </span>&nbsp;<span class=post-category>类别 <a href=/categories/documentation/><i class="far fa-folder fa-fw"></i>documentation</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2022-03-10>2022-03-10</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime=2022-03-10>2022-03-10</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 2876 字&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 6 分钟&nbsp;</div></div><div class=featured-image><img class=lazyload data-src=https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg data-srcset="https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg, https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg 1.5x, https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg 2x" data-sizes=auto alt=https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg title="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling" height=auto width=auto></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><ul><li><a href=#题目>题目</a></li><li><a href=#摘要>摘要</a></li><li><a href=#模型>模型</a><ul><li><a href=#input-layer>Input Layer</a></li><li><a href=#parameter-generation-network>Parameter Generation Network</a></li><li><a href=#output-layers>Output Layers</a></li><li><a href=#language-modeling>Language modeling</a></li><li><a href=#multi-task-learning-algorithm>Multi-Task Learning Algorithm</a></li></ul></li><li><a href=#实验结果与讨论>实验结果与讨论</a></li><li><a href=#结论>结论</a></li><li><a href=#代码>代码</a></li></ul></li></ul></nav></div></div><div class=content id=content><p>ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling 论文解读。</p><h3 id=题目>题目</h3><p>Cross-Domain NER using Cross-Domain Language Modeling [<a href=https://www.aclweb.org/anthology/P19-1236 target=_blank rel="noopener noreffer">ACL 2019]</a> [<a href=https://github.com/jiachenwestlake/Cross-Domain_NER target=_blank rel="noopener noreffer">Code]</a></p><h3 id=摘要>摘要</h3><p>由于标签资源的限制，跨域命名实体识别（Cross-Domain NER）一直是一项具有挑战性的任务。大多数现有的工作都是在监督下进行的，即利用源域和目标域的标记数据。这类方法的一个缺点是，它们不能对没有NER数据的domain进行训练。为了解决这个问题，我们考虑使用跨域的语言模型(LMs)作为NER领域适应的桥梁，通过设计一个新的参数生成网络进行跨域和跨任务的知识转移。结果表明，我们的方法可以有效地从跨域LMs对比中提取域的差异，允许无监督的域适应，同时也给出了最先进的结果。</p><h3 id=模型>模型</h3><p>模型的整体结构如图Fig-1所示。底部展示了两个领域和两个任务的组合。首先给定一个输入句子，通过一个共享的嵌入层计算单词表征，然后通过一个新的参数生成网络计算出一组特定任务和领域的BiLSTM参数，用于编码输入序列，最后不同的输出层被用于不同的任务和领域。</p><div><center><img src=https://i.bmp.ovh/imgs/2022/03/8fc9a7474d79931e.jpg alt=无法显示图片 style=zoom:90%><br>Fig-1.Model architecture</center></div><h4 id=input-layer>Input Layer</h4><p>按照Yang等人（2018）的说法,给定一个输入$\mathbf{x}=[x_1,x_2,\cdots,x_n]$，来自以下4个数据集</p><ul><li><p>源域NER训练集$S_{ner}=\{\{x_i,y_i\}\}_{i=1}^m$</p></li><li><p>目标域NER训练集$T_{ner}=\{\{x_i,y_i\}\}_{i=1}^n$</p></li><li><p>源域原始文本集$S_{lm}=\{\{x_i\}\}_{i=1}^p$</p></li><li><p>目标域原始文本集$T_{lm}=\{\{x_i\}\}_{i=1}^p$</p></li></ul><p>每个词$x_i$被表示为其词嵌入和字符级CNN输出的连接：
$$
\mathbf{v}_i =[\mathbf{e}^w(x_i)\oplus \text{CNN}(\mathbf{e}^c(x_i))]
$$
其中$\mathbf{e}^w$代表一个共享的词嵌入查询表，$\mathbf{e}^c$代表一个共享的字符嵌入查询表。$\text{CNN}(\cdot)$代表一个标准的$\text{CNN}$，作用于一个词$x_i$的字符嵌入序列$\mathbf{e}^c(x_i)$，$\oplus$表示矢量连接。</p><h4 id=parameter-generation-network>Parameter Generation Network</h4><p>将$\mathbf{v}$送入一个双向的LSTM层，为了实现跨领域和跨任务的知识转移，使用一个参数生成网络$f(\cdot,\cdot,\cdot)$动态地生成$\text{BiLSTM}$的参数，由此产生的参数被表示为$\theta_{\text{LSTM}}^{d,t}$，其中$d \in {src,tgt}$，$t\in {ner,lm}$ 分别代表领域标签和任务标签
$$
\theta_{\text{LSTM}}^{d,t} = \mathbf{W} \otimes \mathbf{I}_d^D \otimes \mathbf{I}_t^T
$$
参数解释：</p><ul><li><p>$\mathbf{v}=[{\mathbf{v}_1},{\mathbf{v}_2},\dots,{\mathbf{v}_n}]$表示输入词嵌入</p></li><li><p>$ \mathbf{W}\in \mathbb{R}^{P^{(LSTM)}\times V \times U}$代表一组以三阶张量形式存在的元参数</p></li><li><p>$\mathbf{I}_d^D\in \mathbb{R}^U$代表领域词嵌入</p></li><li><p>$\mathbf{I}_d^D\in \mathbb{R}^V$代表任务词嵌入</p></li><li><p>$U$、 $V$分别代表领域和任务词嵌入的大小</p></li><li><p>$P^{(LSTM)}$是$\text{BiLSTM}$参数的数量</p></li><li><p>$\otimes$ 指张量收缩</p></li></ul><p>给定输入$v$和参数$\theta$，一个任务和特定领域$\text{BiLSTM}$单元的隐藏输出可以统一写成:</p><img src=https://i.bmp.ovh/imgs/2022/03/2f1c264d513dcacc.png style=zoom:50%><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-tex data-lang=tex><span class=line><span class=cl><span class=k>\begin</span><span class=nb>{</span>aligned<span class=nb>}</span>
</span></span><span class=line><span class=cl><span class=k>\overrightarrow</span><span class=nb>{</span><span class=k>\mathbf</span><span class=nb>{</span>h<span class=nb>}}_</span>i<span class=nb>^{</span>d,t<span class=nb>}</span>=<span class=k>\text</span><span class=nb>{</span>LSTM<span class=nb>}</span>(<span class=k>\overrightarrow</span><span class=nb>{</span><span class=k>\mathbf</span><span class=nb>{</span>h<span class=nb>}}_{</span>i-1<span class=nb>}^{</span>d,t<span class=nb>}</span>,<span class=k>\mathbf</span><span class=nb>{</span>v<span class=nb>}_</span>i,<span class=k>\overrightarrow</span><span class=nb>{</span><span class=k>\theta</span><span class=nb>}_{</span><span class=k>\text</span><span class=nb>{</span>LSTM<span class=nb>}}^{</span>d,t<span class=nb>}</span>)<span class=k>\\</span>
</span></span><span class=line><span class=cl><span class=k>\overleftarrow</span><span class=nb>{</span><span class=k>\mathbf</span><span class=nb>{</span>h<span class=nb>}}_{</span>i<span class=nb>}^{</span>d,t<span class=nb>}</span>=<span class=k>\text</span><span class=nb>{</span>LSTM<span class=nb>}</span>(<span class=nb>{</span><span class=k>\overleftarrow</span><span class=nb>{</span><span class=k>\mathbf</span><span class=nb>{</span>h<span class=nb>}}}_{</span>i-1<span class=nb>}^{</span>d,t<span class=nb>}</span>,<span class=k>\mathbf</span><span class=nb>{</span>v<span class=nb>}_</span>i,<span class=k>\overleftarrow</span><span class=nb>{</span><span class=k>\theta</span><span class=nb>}_{</span><span class=k>\text</span><span class=nb>{</span>LSTM<span class=nb>}}^{</span>d,t<span class=nb>}</span>)
</span></span><span class=line><span class=cl><span class=k>\end</span><span class=nb>{</span>aligned<span class=nb>}</span>
</span></span></code></pre></td></tr></table></div></div><p>$\overrightarrow{\mathbf{h}}_i^{d,t}$，$\overleftarrow{\mathbf{h}}_i^{d,t}$分别为前向和后向。</p><h4 id=output-layers>Output Layers</h4><p>标准CRFs被用作NER的输出层，在输入句子$\mathbf{x}$上产生的标签序列$\mathbf{y}=l_1,l_2,\dots,l_i$的输出概率$p(\mathbf{y}\vert \mathbf{x})$是</p><img src=https://i.bmp.ovh/imgs/2022/03/e2126ea6072d8faa.png style=zoom:50%><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-tex data-lang=tex><span class=line><span class=cl><span class=sb>$$</span><span class=nb>
</span></span></span><span class=line><span class=cl><span class=nb>p</span><span class=o>(</span><span class=nv>\boldsymbol</span><span class=nb>{y} </span><span class=nv>\mid</span><span class=nb> </span><span class=nv>\boldsymbol</span><span class=nb>{x}</span><span class=o>)=</span><span class=nv>\frac</span><span class=nb>{</span><span class=nv>\exp</span><span class=nb> </span><span class=nv>\left\{\sum</span><span class=nb>_{i}</span><span class=nv>\left</span><span class=o>(</span><span class=nv>\mathbf</span><span class=nb>{w}_{</span><span class=nv>\mathrm</span><span class=nb>{CRF}}^{l_{i}} </span><span class=nv>\cdot</span><span class=nb> </span><span class=nv>\mathbf</span><span class=nb>{h}_{i}</span><span class=o>+</span><span class=nb>b_{</span><span class=nv>\mathrm</span><span class=nb>{CRF}}^{</span><span class=nv>\left</span><span class=o>(</span><span class=nb>l_{i</span><span class=o>-</span><span class=m>1</span><span class=nb>}, l_{i}</span><span class=nv>\right</span><span class=o>)</span><span class=nb>}</span><span class=nv>\right</span><span class=o>)</span><span class=nv>\right\}</span><span class=nb>}{</span><span class=nv>\sum</span><span class=nb>_{</span><span class=nv>\boldsymbol</span><span class=nb>{y}^{</span><span class=nv>\prime</span><span class=nb>}} </span><span class=nv>\exp</span><span class=nb> </span><span class=nv>\left\{\sum</span><span class=nb>_{i}</span><span class=nv>\left</span><span class=o>(</span><span class=nv>\mathbf</span><span class=nb>{w}_{i}^{l_{</span><span class=nv>\mathrm</span><span class=nb>{CRF}}^{</span><span class=nv>\prime</span><span class=nb>}} </span><span class=nv>\cdot</span><span class=nb> </span><span class=nv>\mathbf</span><span class=nb>{h}_{i}</span><span class=o>+</span><span class=nb>b_{</span><span class=nv>\mathrm</span><span class=nb>{CRF}}^{</span><span class=nv>\left</span><span class=o>(</span><span class=nb>l_{i</span><span class=o>-</span><span class=m>1</span><span class=nb>}^{</span><span class=nv>\prime</span><span class=nb>}, l_{i}^{</span><span class=nv>\prime</span><span class=nb>}</span><span class=nv>\right</span><span class=o>)</span><span class=nb>}</span><span class=nv>\right</span><span class=o>)</span><span class=nv>\right\}</span><span class=nb>}
</span></span></span><span class=line><span class=cl><span class=nb></span><span class=s>$$</span>
</span></span></code></pre></td></tr></table></div></div><p>参数解释：</p><ul><li><p>$\mathbf{h}=[\overrightarrow{\mathbf{h}}_1 \otimes \overleftarrow{\mathbf{h}}_1,\dots,\overrightarrow{\mathbf{h}}_n \otimes \overleftarrow{\mathbf{h}}_n]$代表前向和后向的组合特征</p></li><li><p>$y&rsquo;$代表一个任意的标签序列</p></li><li><p>$\mathbf{w}^{li}_{CRF}$是$l_i$特有的模型参数</p></li><li><p>${b_{CRF}^{(l_{i-1},l_i)}}$ 是 $l_{i-1}$ 和 $l_i$特有的偏置</p></li></ul><p>考虑到不同领域的NER标签集可能不同，在Fig-1中分别用$\text{CRF(S)}$和$\text{CRF(T)}$来表示源域和目标域的$\text{CRFs}$，使用一阶Viterbi算法来寻找高分的标签序列。</p><h4 id=language-modeling>Language modeling</h4><p>前向$\text{LM(LMf)}$ 使用前向LSTM隐藏状态$\overrightarrow{\mathbf{h}}=[\overrightarrow{\mathbf{h}}_1,\dots,\overrightarrow{\mathbf{h}}_n]$：</p><ul><li>在给定$x_{1:i}$情况下来计算下一个词$x_{i+1}$的概率，表示为$p^f (x_{i+1}\vert x_{1:i})$</li></ul><p>后向$\text{LM(LMb)}$ 使用后向LSTM隐藏状态$\overleftarrow{\mathbf{h}}=[\overleftarrow{\mathbf{h}}_1,\dots,\overleftarrow{\mathbf{h}}_n]$：</p><ul><li>在给定$x_{i:n}$情况下来计算上一个词$x_{i-1}$的概率，表示为$p^f (x_{i-1}\vert x_{i:n})$</li></ul><p>考虑到计算效率，采用负采样Softmax（NSSoftmax）来计算前向和后向概率，具体如下：</p><img src=https://i.bmp.ovh/imgs/2022/03/89ee46cafad38527.png style=zoom:50%><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-tex data-lang=tex><span class=line><span class=cl><span class=sb>$$</span><span class=nb>
</span></span></span><span class=line><span class=cl><span class=nb></span><span class=nv>\begin</span><span class=nb>{aligned}
</span></span></span><span class=line><span class=cl><span class=nb>&amp;p^{f}</span><span class=nv>\left</span><span class=o>(</span><span class=nb>x_{i</span><span class=o>+</span><span class=m>1</span><span class=nb>} </span><span class=nv>\mid</span><span class=nb> x_{</span><span class=m>1</span><span class=nb>: i}</span><span class=nv>\right</span><span class=o>)=</span><span class=nv>\frac</span><span class=nb>{</span><span class=m>1</span><span class=nb>}{Z} </span><span class=nv>\exp</span><span class=nb> </span><span class=nv>\left\{\mathbf</span><span class=nb>{w}_{</span><span class=nv>\#</span><span class=nb> x_{i</span><span class=o>+</span><span class=m>1</span><span class=nb>}}^{</span><span class=nv>\top</span><span class=nb>} </span><span class=nv>\overrightarrow</span><span class=nb>{</span><span class=nv>\mathbf</span><span class=nb>{h}}_{i}</span><span class=o>+</span><span class=nb>b_{</span><span class=nv>\#</span><span class=nb> x_{i</span><span class=o>+</span><span class=m>1</span><span class=nb>}}</span><span class=nv>\right\}</span><span class=nb> </span><span class=nv>\\</span><span class=nb>
</span></span></span><span class=line><span class=cl><span class=nb>&amp;p^{b}</span><span class=nv>\left</span><span class=o>(</span><span class=nb>x_{i</span><span class=o>-</span><span class=m>1</span><span class=nb>} </span><span class=nv>\mid</span><span class=nb> x_{i: n}</span><span class=nv>\right</span><span class=o>)=</span><span class=nv>\frac</span><span class=nb>{</span><span class=m>1</span><span class=nb>}{Z} </span><span class=nv>\exp</span><span class=nb> </span><span class=nv>\left\{\mathbf</span><span class=nb>{w}_{</span><span class=nv>\#</span><span class=nb> x_{i</span><span class=o>-</span><span class=m>1</span><span class=nb>}}^{</span><span class=nv>\top</span><span class=nb>} </span><span class=nv>\overleftarrow</span><span class=nb>{</span><span class=nv>\mathbf</span><span class=nb>{h}}_{i}</span><span class=o>+</span><span class=nb>b_{</span><span class=nv>\#</span><span class=nb> x_{i</span><span class=o>-</span><span class=m>1</span><span class=nb>}}</span><span class=nv>\right\}</span><span class=nb>
</span></span></span><span class=line><span class=cl><span class=nb></span><span class=nv>\end</span><span class=nb>{aligned}
</span></span></span><span class=line><span class=cl><span class=nb></span><span class=s>$$</span>
</span></span></code></pre></td></tr></table></div></div><p>其中</p><ul><li><p>${\#}x$代表目标词$x$的词汇索引</p></li><li><p>$\boldsymbol{w_{\# x}}$和$b_{\#x}$分别为目标词向量和目标词bias</p></li><li><p>$Z$是归一化项目，计算公式为:</p><img src=https://i.bmp.ovh/imgs/2022/03/780747805e0cf3d3.png style=zoom:50%><p>其中$\mathcal{N}_x$代表目标词$x$的nagative样本集，该集的每个元素都是1到跨域词汇量的随机数，$\bar{\mathbf{h}}i$分别代表LMf中的$\overrightarrow{\mathbf{h}}_i$和LMb中的$\overleftarrow{\mathbf{h}}_i$。</p></li></ul><h4 id=multi-task-learning-algorithm>Multi-Task Learning Algorithm</h4><p>我们为多任务学习提出了一种跨任务和跨领域的联合训练方法，算法1提供了训练程序。在每轮训练中（第1行至第18行），Fig-1中4个任务按照mini-batches轮流训练（分别为第4-5、7-8、11-12和15-16行）</p><ul><li>每个任务首先使用$\boldsymbol{W}$和他们的表示$\boldsymbol{I_d^D}$、$\boldsymbol{I_t^T}$生成参数$\theta_{\text{LSTM}}^{d,t}$</li><li>然后计算$f(\boldsymbol{W},\boldsymbol{I_d^D},\boldsymbol{I_t^T})$的梯度，以及特定领域的输出层$(\theta_{crfs},\theta_{crft},\theta_{nss})$</li></ul><img src=https://i.bmp.ovh/imgs/2022/03/b843dcf41fdf74eb.png style=zoom:50%><h3 id=实验结果与讨论>实验结果与讨论</h3><p>作者在三个跨领域数据集上进行了实验，在有监督的领域适应和无监督的领域适应设置下，将提出的方法与一系列转移学习基线进行比较。</p><img src=https://i.bmp.ovh/imgs/2022/03/de890530165b5d27.png style=zoom:50%>
<img src=https://i.bmp.ovh/imgs/2022/03/24ed2cc5588a8f10.png style=zoom:50%><h3 id=结论>结论</h3><p>通过从原始文本中提取领域差异的知识来进行NER领域适应。为了实现这一目标，作者通过一个新的参数生成网络进行跨领域语言建模，该网络将领域和任务知识分解为两组嵌入向量。在三个数据集上的实验表明，方法在有监督的领域适应方法中是非常有效的，同时允许在无监督的领域适应中进行zero-shot学习。</p><h3 id=代码>代码</h3><p><a href=https://github.com/jiachenwestlake/Cross-Domain_NER target=_blank rel="noopener noreffer">https://github.com/jiachenwestlake/Cross-Domain_NER</a></p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2022-03-10</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=# onclick=return!1 title="分享到 Twitter" data-sharer=twitter data-url=https://kevinzhangcode.github.io/paper03/ data-title="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling" data-hashtags="NER,NLP,Domain Adaptation"><i class="fab fa-twitter fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Facebook" data-sharer=facebook data-url=https://kevinzhangcode.github.io/paper03/ data-hashtag=NER><i class="fab fa-facebook-square fa-fw"></i></a><a href=# onclick=return!1 title="分享到 WhatsApp" data-sharer=whatsapp data-url=https://kevinzhangcode.github.io/paper03/ data-title="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Line" data-sharer=line data-url=https://kevinzhangcode.github.io/paper03/ data-title="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling"><i data-svg-src=/lib/simple-icons/icons/line.min.svg></i></a><a href=# onclick=return!1 title="分享到 微博" data-sharer=weibo data-url=https://kevinzhangcode.github.io/paper03/ data-title="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling" data-image=https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg><i class="fab fa-weibo fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Myspace" data-sharer=myspace data-url=https://kevinzhangcode.github.io/paper03/ data-title="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling" data-description="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling"><i data-svg-src=/lib/simple-icons/icons/myspace.min.svg></i></a><a href=# onclick=return!1 title="分享到 Blogger" data-sharer=blogger data-url=https://kevinzhangcode.github.io/paper03/ data-title="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling" data-description="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling"><i class="fab fa-blogger fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Evernote" data-sharer=evernote data-url=https://kevinzhangcode.github.io/paper03/ data-title="ACl-2019-Cross-Domain NER using Cross-Domain Language Modeling"><i class="fab fa-evernote fa-fw"></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/ner/>NER</a>,&nbsp;<a href=/tags/nlp/>NLP</a>,&nbsp;<a href=/tags/domain-adaptation/>Domain Adaptation</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/tools01/ class=prev rel=prev title="Transformers Domain Adaptation"><i class="fas fa-angle-left fa-fw"></i>Transformers Domain Adaptation</a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>由 <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.94.0">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/HEIGE-PCloud/DoIt target=_blank rel="noopener noreffer" title="DoIt 0.2.13"><i class="far fa-edit fa-fw"></i> DoIt</a></div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=kevinzhangcode.github.io target=_blank rel="noopener noreferrer">youguan</a></span></div></div></footer></div><div id=fixed-buttons><a href=#back-to-top id=back-to-top-button class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw"></i></a></div><div class=assets><script type=text/javascript src=/lib/autocomplete/autocomplete.min.js></script><script type=text/javascript src=/lib/lunr/lunr.min.js></script><script type=text/javascript src=/lib/lunr/lunr.stemmer.support.min.js></script><script type=text/javascript src=/lib/lunr/lunr.zh.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/topbar/topbar.min.js></script><script type=text/javascript src=/lib/pjax/pjax.min.js></script><script type=text/javascript src=/js/theme.min.js></script></div><div class=pjax-assets><script type=text/javascript src=/lib/lightgallery/lightgallery.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-thumbnail.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-zoom.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js></script><script type=text/javascript src=/lib/katex/auto-render.min.js></script><script type=text/javascript src=/lib/katex/copy-tex.min.js></script><script type=text/javascript src=/lib/katex/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:1e3},comment:{},lightGallery:{actualSize:!1,exThumbImage:"data-thumbnail",hideBarsDelay:2e3,selector:".lightgallery",speed:400,thumbContHeight:80,thumbWidth:80,thumbnail:!0},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",lunrLanguageCode:"zh",lunrSegmentitURL:"/lib/lunr/lunr.segmentit.js",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"lunr"},sharerjs:!0}</script><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/lightgallery/lightgallery.min.css><noscript><link rel=stylesheet href=/lib/lightgallery/lightgallery.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/katex.min.css><noscript><link rel=stylesheet href=/lib/katex/katex.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.css><noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.css></noscript></div></body></html>