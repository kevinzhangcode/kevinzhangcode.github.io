<!doctype html><html lang=zh-cn>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=robots content="noodp">
<title class=pjax-title>ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition - kevinzhang'blog</title><meta name=Description content="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition"><meta property="og:title" content="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition">
<meta property="og:description" content="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition">
<meta property="og:type" content="article">
<meta property="og:url" content="https://kevinzhangcode.github.io/paper01/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2022-03-03T21:49:49+08:00">
<meta property="article:modified_time" content="2022-03-03T21:49:49+08:00">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition">
<meta name=twitter:description content="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition">
<meta name=application-name content="kevinzhang'blog">
<meta name=apple-mobile-web-app-title content="kevinzhang'blog">
<meta name=theme-color content="#f8f8f8"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico>
<link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=canonical href=https://kevinzhangcode.github.io/paper01/><link rel=prev href=https://kevinzhangcode.github.io/nnlm/><link rel=next href=https://kevinzhangcode.github.io/paper02/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/fontawesome-free/all.min.css>
<noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/animate/animate.min.css>
<noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/kevinzhangcode.github.io\/paper01\/"},"genre":"posts","keywords":"NER, NLP, Domain Adaptation","wordcount":2922,"url":"https:\/\/kevinzhangcode.github.io\/paper01\/","datePublished":"2022-03-03T21:49:49+08:00","dateModified":"2022-03-03T21:49:49+08:00","publisher":{"@type":"Organization","name":"youguan"},"author":{"@type":"Person","name":"youguan"},"description":"ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition"}</script></head><body header-desktop header-mobile><script type=text/javascript>function setTheme(e){document.body.setAttribute("theme",e)}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(t){const e=document.getElementsByTagName("meta");for(let n=0;n<e.length;n++)if(e[n].getAttribute("name")===t)return e[n];return''}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"||e==="black"?setTheme(e):window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?setTheme("dark"):setTheme("light")}else''==="light"||''==="dark"||''==="black"?(setTheme(''),saveTheme('')):(saveTheme("auto"),window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?setTheme("dark"):setTheme("light"));let metaColors={light:"#f8f8f8",dark:"#252627",black:"#000000"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")]</script>
<div id=back-to-top></div><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop>
<div class=header-wrapper>
<div class=header-title>
<a href=/ title="kevinzhang'blog">kevinzhang'blog</a>
</div><div class=menu>
<div class=menu-inner><a class=menu-item href=/posts/> 文章 </a><a class=menu-item href=/tags/> 标签 </a><a class=menu-item href=/categories/> 分类 </a><a class=menu-item href=/about/> 关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索文章标题或内容... id=search-input-desktop>
<a href=# onclick=return!1 class="search-button search-toggle" id=search-toggle-desktop title=搜索>
<i class="fas fa-search fa-fw"></i>
</a>
<a href=# onclick=return!1 class="search-button search-clear" id=search-clear-desktop title=清空>
<i class="fas fa-times-circle fa-fw"></i>
</a>
<span class="search-button search-loading" id=search-loading-desktop>
<i class="fas fa-spinner fa-fw fa-spin"></i>
</span>
</span><a href=# onclick=return!1 class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i>
</a></div></div></div></header><header class=mobile id=header-mobile>
<div class=header-container>
<div class=header-wrapper>
<div class=header-title>
<a href=/ title="kevinzhang'blog">kevinzhang'blog</a>
</div><div class=menu-toggle id=menu-toggle-mobile>
<span></span><span></span><span></span>
</div></div><div class=menu id=menu-mobile><div class=search-wrapper>
<div class="search mobile" id=search-mobile>
<input type=text placeholder=搜索文章标题或内容... id=search-input-mobile>
<a href=# onclick=return!1 class="search-button search-toggle" id=search-toggle-mobile title=搜索>
<i class="fas fa-search fa-fw"></i>
</a>
<a href=# onclick=return!1 class="search-button search-clear" id=search-clear-mobile title=清空>
<i class="fas fa-times-circle fa-fw"></i>
</a>
<span class="search-button search-loading" id=search-loading-mobile>
<i class="fas fa-spinner fa-fw fa-spin"></i>
</span>
</div><a href=# onclick=return!1 class=search-cancel id=search-cancel-mobile>
取消
</a>
</div><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a href=# onclick=return!1 class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i>
</a></div></div></header><div class="search-dropdown desktop">
<div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile">
<div id=search-dropdown-mobile></div></div><main class=main>
<div class=container><div class=toc id=toc-auto>
<h2 class=toc-title>目录</h2><div class="toc-content always-active" id=toc-content-auto></div></div><script>document.getElementsByTagName("main")[0].setAttribute("pageStyle","normal")</script><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition</h1><div class=post-meta>
<div class=post-meta-line>
<span class=post-author><i class="author fas fa-user-circle fa-fw"></i><a href=kevinzhangcode.github.io title=Author rel=author class=author>youguan</a>
</span>&nbsp;<span class=post-category>收录于 </span>&nbsp;<span class=post-category>类别 <a href=/categories/documentation/><i class="far fa-folder fa-fw"></i>documentation</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2022-03-03>2022-03-03</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime=2022-03-03>2022-03-03</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 2922 字&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 6 分钟&nbsp;</div></div><div class=featured-image><img class=lazyload data-src=https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg data-srcset="https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg, https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg 1.5x, https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg 2x" data-sizes=auto alt=https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg title="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition" height=auto width=auto></div><div class="details toc" id=toc-static kept>
<div class="details-summary toc-title">
<span>目录</span>
<span><i class="details-icon fas fa-angle-right"></i></span>
</div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents>
<ul>
<li>
<ul>
<li><a href=#题目>题目</a></li><li><a href=#摘要>摘要</a></li><li><a href=#贡献>贡献</a></li><li><a href=#模型架构>模型架构</a>
<ul>
<li><a href=#词表示层word-representation>词表示层（word representation）</a></li><li><a href=#注释者切换器层annotator-switcher>注释者切换器层（annotator switcher）</a></li><li><a href=#bilstm编码层bilstm-encoding>BiLSTM编码层（BiLSTM Encoding）</a></li><li><a href=#crf层crf-inference-and-training>CRF层（CRF inference and training）</a></li></ul></li><li><a href=#结果与讨论>结果与讨论</a></li><li><a href=#代码解读>代码解读</a></li></ul></li></ul></nav></div></div><div class=content id=content><p>ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition 论文解读。</p><h3 id=题目>题目</h3><p>Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition [<a href=https://arxiv.org/pdf/2105.14980v1.pdf target=_blank rel="noopener noreffer">ACL 2021 Long</a>] [<a href=https://github.com/izhx/CLasDA target=_blank rel="noopener noreffer"><strong>Code</strong></a>]</p><h3 id=摘要>摘要</h3><p>众包被认为是有效监督学习的一个前瞻性解决方案，旨在通过群体劳动建立大规模的注释训练数据。以前的研究集中在减少众包注解的噪音对监督模式的影响。在这项工作中，我们采取了不同的观点，将所有众包注释重新视为与个别数据标注师有关的黄金标准。通过这种方式，我们发现众包可以与领域适应性（domain adaptation）高度相似，那么最近的跨领域方法的进展几乎可以直接应用于众包。在这里，我们以命名实体识别（NER）为研究案例，提出了一个<code>Annotator-aware</code>的表示学习模型，该模型受到领域适应方法的启发，试图捕捉有效的<code>Domain-aware</code>的特征。我们研究了无监督和有监督的众包学习，假设没有或只有小规模的专家注释可用，在一个基准的众包NER数据集上的实验结果表明，我们的方法是非常有效的，表现了一个新的最先进的性能。此外，在有监督的情况下，我们只需要很小规模的专家注释就可以获得令人印象深刻的性能提升。</p><h3 id=贡献>贡献</h3><ul>
<li>
<p>对众包学习提出了不同的看法，并建议将众包学习转化为领域适应问题（domain adaptation），这自然而然地将NLP的两个重要主题联系起来。</p></li><li>
<p>提出了一种新型的众包学习方法。尽管该方法在领域适应方面的新颖性有限，但它是第一项关于众包学习的工作，并能在NER上取得最先进的性能。</p></li><li>
<p>首次引入了有监督的众包学习，这是从领域适应性中借来的，将是NLP任务的一个前瞻性解决方案。</p></li></ul><h3 id=模型架构>模型架构</h3><p>包括四个部分：</p><p>(1) word representation</p><p>(2) annotator switcher</p><p>(3) BiLSTM Encoding</p><p>(4) CRF inference and training.</p><div>
<center>
<img src=https://i.bmp.ovh/imgs/2022/03/db2ee517bcc61dcb.png alt=无法显示图片 style=zoom:90%>
<br>
Fig-1.模型结构
</center>
</div><h4 id=词表示层word-representation>词表示层（word representation）</h4><p>假设存在一个包含$n$个单词的句子$w_1 \dots w_n$,我们首先通过<a href=http://proceedings.mlr.press/v97/houlsby19a.html target=_blank rel="noopener noreffer">$\texttt{Adapter} \circ \texttt{BERT}$</a>将其转换为矢量表征.</p><p>$$
e_1 \dots e_n = \texttt{Adapter} \circ \texttt{BERT}(w_1 \dots w_n)
$$</p><p>注意：值得注意的是，<a href=http://proceedings.mlr.press/v97/houlsby19a.html target=_blank rel="noopener noreffer">$\texttt{Adapter} \circ \texttt{BERT}$</a>方法不再需要对庞大的BERT参数进行微调，而是通过调整轻得多的适配器参数来获得相当的性能。因此通过这种方式，可以很容易地将词的表示法扩展为<code>annotator-aware</code>的表示法。</p><h4 id=注释者切换器层annotator-switcher>注释者切换器层（annotator switcher）</h4><p>作者目标是有效地学习不同数据标注师意识到的词汇特征，这可以被视为对个别注释者的上下文理解。因此，引入了一个注释者切换器，以支持带有注释者输入的$\texttt{Adapter} \circ \texttt{BERT}$，其灵感来自于<a href=https://aclanthology.org/D18-1039/ target=_blank rel="noopener noreffer">Parameter Generation Network (PGN)</a>，其关键思想是使用参数生成网络（PGN），通过输入annotators动态地产生适配器参数。通过这种方式，模型可以在不同的annotators之间灵活地切换。</p><p>具体来说，假设$V$是所有适配器参数的矢量形式，通过打包操作，也可以解包恢复所有的适配器参数，PGN模块就是根据annotators的输入动态生成<a href=http://proceedings.mlr.press/v97/houlsby19a.html target=_blank rel="noopener noreffer">$\texttt{Adapter} \circ \texttt{BERT}$</a>的$V$，如模型图中右边的橙色部分所示，切换器switcher可以被形式化为：</p><p>$$
\begin{align}
\textbf{x} &=\textbf{r}_1&rsquo; \dots \textbf{n}_1&rsquo;\\
&=\textbf{PGN} \circ \textbf{Adapter} \circ \textbf{BERT}(x,a)\\
&=\textbf{Adapter} \circ \textbf{BERT}(x,\textbf{V}=\mathbf{\Theta} \times \textbf{e}^a)
\end{align}
$$</p><p>其中$\mathbf{\Theta} \in \mathcal{R}^{\vert \textbf{V} \vert \times\textbf{e}^a}$，$\textbf{x} =\textbf{r}_1&rsquo; \dots \textbf{n}_1&rsquo;$是注释者$a$对$x=w_1 \dots w_n$的<code>annotator-aware</code>的表示，$\textbf{e}^a$是annotator的embedding。</p><h4 id=bilstm编码层bilstm-encoding>BiLSTM编码层（BiLSTM Encoding）</h4><p><a href=http://proceedings.mlr.press/v97/houlsby19a.html target=_blank rel="noopener noreffer">$\texttt{Adapter} \circ \texttt{BERT}$</a>需要一个额外的面向任务的模块来进行高级特征提取。在这里利用单一的BiLSTM层来实现：$h_1 \dots h_n = \texttt{BiLSTM}(x)$，用于下一步的推理和训练。</p><h4 id=crf层crf-inference-and-training>CRF层（CRF inference and training）</h4><p>最后使用<code>CRF</code>来计算候选顺序输出$y = l_1 \dots l_n$的全局得分。</p><p>$$
\begin{align}
{\textbf{o}_i} &=\textbf{W}^{crf} {\textbf{h}_i}+\textbf{b}^{crf} \
\end{align}
$$</p><p>$$
\begin{align}
{\sum_{i=1}^n} (\textbf{T}[l_{i-1},l_i]+{\textbf{o}_i}[l_i])
\end{align}
$$</p><p>其中$\textbf{W}^{crf}、 \textbf{b}^{crf}、 \textbf{T}$是模型的参数。给定一个输入$(x，a)$，通过维特比算法进行推理,对于训练，定义了一个句子级别的交叉熵目标。
$$
\begin{align}
p(y^a \vert x,a) &=\frac{\exp{\texttt{score}(y^a \vert x,a)}}{\sum_y \exp{\texttt{score}(y \vert x,a)}}\\
\mathcal{L} &=-\log{(y^a \vert x,a)}
\end{align}
$$
其中$y^a$是$a$对$x$的黄金标准输出，$y$属于所有可能的候选人，$p(y^a|x, a)$表示句子级的概率。</p><h3 id=结果与讨论>结果与讨论</h3><div>
<center>
<img src=https://i.bmp.ovh/imgs/2022/03/9098737e2db2df88.png alt=无法显示图片 style=zoom:80%>
<br>
Fig-1.无监督学习的实验结果
</center>
</div><p>Fig-1显示了无监督情况下的测试结果。从整体上看，我们可以看到表征学习模型通过借用了<code>Domain Adaptation</code>，可以达到最好的性能，F1得分达到77.95，明显优于第二好的模型<code>LC-cat</code>。 这一结果表明我们的方法比其他模型更有优势。通过深入研究结果，我们可以发现，&ldquo;annotator-aware"模型明显优于 &ldquo;annotator-agnostic &ldquo;模型，表明注释者信息对众包学习有很大帮助，这个观察结果进一步显示了通过将注释者与领域相一致的合理性，因为领域信息对于领域适应也是有用的。此外，我们的表征学习方法在“annotator-aware”模型中的表现更好，表明模型可以更有效地捕捉注释者感知的信息，因为我们的出发点完全不同。我们并不试图对基于众包注释的专家标签进行建模。</p><div>
<center>
<img src=https://i.bmp.ovh/imgs/2022/03/1a7468db109474d7.png alt=无法显示图片 style=zoom:90%>
<br>
Fig-2.有监督学习的实验结果
</center>
</div><p>为了研究有监督情况，我们假设所有众包句子的专家注释是可用的。除了探索完整的专家注释，我们还研究了另外三种不同的情况，即在无监督环境下逐步增加专家注释，目的是研究我们的模型在小规模专家注释下的有效性。具体来说，我们<code>假设专家注释的比例为1%、5%、25%和100%</code>。Fig-2显示了所有的结果，包括我们的四个baselines和一个只基于专家注释的黄金模型进行比较。总的来说，我们可以看到，我们的表征学习模型可以为所有的场景带来最好的表现，证明它在监督学习中也是有效的。接下来，通过比较注释者无关(annotator-agnostic)模型和注释者意识(annotator-aware)模型，我们可以看到annotator-aware模型更好，这与无监督的设置是一致的。更有趣的是，结果显示，在专家注释规模很小的情况下（1%和5%），<code>All</code>比<code>gold</code>好，而只有在有足够的专家注释时（25%和100%），这一趋势才会逆转。该观察表明，当黄金注释(gold annotations)不足时，众包注释(crowdsourced annotations)总是有帮助的。此外，我们很容易理解<code>MV</code>比<code>gold</code>差，因为后者的训练语料质量更高。</p><p>此外，我们发现，即使是增加注释者意识(annotator-aware)机制的LC和LC-cat模型也无法获得与<code>gold</code>相比的任何积极影响，这表明从众包注释中提炼基础真理可能不是最有希望的解决方案，而我们的表征学习模型可以持续给出比黄金更好的结果，表明众包注释对我们的方法总是有帮助。通过将众包学习视为领域适应，我们不再将众包注释视为噪音，相反，它们被视为可转移的知识，类似于源领域和目标领域之间的关系。因此，它们可以一直以这种方式发挥作用。</p><h3 id=代码解读>代码解读</h3><p>待复现</p></div><div class=post-footer id=post-footer>
<div class=post-info>
<div class=post-info-line>
<div class=post-info-mod>
<span>更新于 2022-03-03</span>
</div><div class=post-info-license></div></div><div class=post-info-line>
<div class=post-info-md></div><div class=post-info-share>
<span><a href=# onclick=return!1 title="分享到 Twitter" data-sharer=twitter data-url=https://kevinzhangcode.github.io/paper01/ data-title="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition" data-hashtags="NER,NLP,Domain Adaptation"><i class="fab fa-twitter fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Facebook" data-sharer=facebook data-url=https://kevinzhangcode.github.io/paper01/ data-hashtag=NER><i class="fab fa-facebook-square fa-fw"></i></a><a href=# onclick=return!1 title="分享到 WhatsApp" data-sharer=whatsapp data-url=https://kevinzhangcode.github.io/paper01/ data-title="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Line" data-sharer=line data-url=https://kevinzhangcode.github.io/paper01/ data-title="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition"><i data-svg-src=/lib/simple-icons/icons/line.min.svg></i></a><a href=# onclick=return!1 title="分享到 微博" data-sharer=weibo data-url=https://kevinzhangcode.github.io/paper01/ data-title="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition" data-image=https://editor.analyticsvidhya.com/uploads/19617Intro%20image.jpg><i class="fab fa-weibo fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Myspace" data-sharer=myspace data-url=https://kevinzhangcode.github.io/paper01/ data-title="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition" data-description="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition"><i data-svg-src=/lib/simple-icons/icons/myspace.min.svg></i></a><a href=# onclick=return!1 title="分享到 Blogger" data-sharer=blogger data-url=https://kevinzhangcode.github.io/paper01/ data-title="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition" data-description="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition"><i class="fab fa-blogger fa-fw"></i></a><a href=# onclick=return!1 title="分享到 Evernote" data-sharer=evernote data-url=https://kevinzhangcode.github.io/paper01/ data-title="ACl-2021-Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition"><i class="fab fa-evernote fa-fw"></i></a></span>
</div></div></div><div class=post-info-more>
<section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/ner/>NER</a>,&nbsp;<a href=/tags/nlp/>NLP</a>,&nbsp;<a href=/tags/domain-adaptation/>Domain Adaptation</a></section><section>
<span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span>
</section></div><div class=post-nav><a href=/nnlm/ class=prev rel=prev title="01-NNLM(’A Neural Probabilistic Language Model‘) "><i class="fas fa-angle-left fa-fw"></i>01-NNLM(’A Neural Probabilistic Language Model‘) </a>
<a href=/paper02/ class=next rel=next title="ACl-2021-Learning Domain-Specialised Representations for Cross-Lingual Biomedical Entity Linking">ACl-2021-Learning Domain-Specialised Representations for Cross-Lingual Biomedical Entity Linking<i class="fas fa-angle-right fa-fw"></i></a></div></div></article></div></main><footer class=footer>
<div class=footer-container><div class=footer-line>由 <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.93.2">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/HEIGE-PCloud/DoIt target=_blank rel="noopener noreffer" title="DoIt 0.2.13"><i class="far fa-edit fa-fw"></i> DoIt</a>
</div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=kevinzhangcode.github.io target=_blank rel="noopener noreferrer">youguan</a></span></div></div></footer></div><div id=fixed-buttons><a href=#back-to-top id=back-to-top-button class=fixed-button title=回到顶部>
<i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title=查看评论>
<i class="fas fa-comment fa-fw"></i>
</a>
</div><div class=assets><script type=text/javascript src=/lib/autocomplete/autocomplete.min.js></script><script type=text/javascript src=/lib/lunr/lunr.min.js></script><script type=text/javascript src=/lib/lunr/lunr.stemmer.support.min.js></script><script type=text/javascript src=/lib/lunr/lunr.zh.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/topbar/topbar.min.js></script><script type=text/javascript src=/lib/pjax/pjax.min.js></script><script type=text/javascript src=/js/theme.min.js></script></div><div class=pjax-assets><script type=text/javascript src=/lib/lightgallery/lightgallery.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-thumbnail.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-zoom.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js></script><script type=text/javascript src=/lib/katex/auto-render.min.js></script><script type=text/javascript src=/lib/katex/copy-tex.min.js></script><script type=text/javascript src=/lib/katex/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:1e3},comment:{},lightGallery:{actualSize:!1,exThumbImage:"data-thumbnail",hideBarsDelay:2e3,selector:".lightgallery",speed:400,thumbContHeight:80,thumbWidth:80,thumbnail:!0},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",lunrLanguageCode:"zh",lunrSegmentitURL:"/lib/lunr/lunr.segmentit.js",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"lunr"},sharerjs:!0}</script><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/lightgallery/lightgallery.min.css>
<noscript><link rel=stylesheet href=/lib/lightgallery/lightgallery.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/katex.min.css>
<noscript><link rel=stylesheet href=/lib/katex/katex.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.css>
<noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.css></noscript></div></body></html>